{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEA-Flow Tutorial: Comprehensive Analysis of Multi-Electrode Array Data\n",
    "\n",
    "This notebook demonstrates the complete workflow for analyzing MEA data using the MEA-Flow library, focusing on neural population dynamics and comparative analysis across experimental conditions.\n",
    "\n",
    "## Overview\n",
    "\n",
    "MEA-Flow provides a comprehensive pipeline for:\n",
    "1. **Data Loading**: Support for various MEA data formats (.spk, .mat, CSV)\n",
    "2. **Metrics Calculation**: Activity, regularity, and synchrony measures\n",
    "3. **Manifold Analysis**: Population geometry and dimensionality reduction\n",
    "4. **Visualization**: Publication-ready plots and visualizations\n",
    "5. **Comparative Analysis**: Cross-condition statistical comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T18:16:42.140824Z",
     "iopub.status.busy": "2025-08-28T18:16:42.140642Z",
     "iopub.status.idle": "2025-08-28T18:16:43.284694Z",
     "shell.execute_reply": "2025-08-28T18:16:43.284135Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_multiple_files' from 'mea_flow' (/home/neuro/repos/mea-flow/src/mea_flow/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mUserWarning\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# MEA-Flow imports\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmea_flow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Data loading and processing\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     SpikeList, load_data, load_multiple_files,\n\u001b[1;32m     14\u001b[0m     \n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Analysis modules\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     MEAMetrics, ManifoldAnalysis,\n\u001b[1;32m     17\u001b[0m     \n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Visualization\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     MEAPlotter,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmea_flow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalysis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AnalysisConfig\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmea_flow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanifold\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ManifoldConfig\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_multiple_files' from 'mea_flow' (/home/neuro/repos/mea-flow/src/mea_flow/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# MEA-Flow imports\n",
    "from mea_flow import (\n",
    "    # Data loading and processing\n",
    "    SpikeList, load_data, load_multiple_files,\n",
    "    \n",
    "    # Analysis modules\n",
    "    MEAMetrics, ManifoldAnalysis,\n",
    "    \n",
    "    # Visualization\n",
    "    MEAPlotter,\n",
    ")\n",
    "\n",
    "from mea_flow.analysis import AnalysisConfig\n",
    "from mea_flow.manifold import ManifoldConfig\n",
    "from mea_flow.utils import get_default_parameters, setup_logging\n",
    "\n",
    "# Set up logging\n",
    "logger = setup_logging('INFO')\n",
    "\n",
    "print(\"MEA-Flow Tutorial - Ready to begin!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Initial Exploration\n",
    "\n",
    "We'll demonstrate loading MEA data from different formats and explore the basic structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T18:16:43.309299Z",
     "iopub.status.busy": "2025-08-28T18:16:43.309080Z",
     "iopub.status.idle": "2025-08-28T18:16:43.577396Z",
     "shell.execute_reply": "2025-08-28T18:16:43.576724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating synthetic data for condition: control\n",
      "  - Channels: 64\n",
      "  - Active channels: 64\n",
      "  - Total spikes: 62718\n",
      "  - Recording length: 300.0 s\n",
      "\n",
      "Creating synthetic data for condition: treatment1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Channels: 64\n",
      "  - Active channels: 64\n",
      "  - Total spikes: 95075\n",
      "  - Recording length: 300.0 s\n",
      "\n",
      "Creating synthetic data for condition: treatment2\n",
      "  - Channels: 64\n",
      "  - Active channels: 64\n",
      "  - Total spikes: 43189\n",
      "  - Recording length: 300.0 s\n",
      "\n",
      "Data loading completed!\n"
     ]
    }
   ],
   "source": [
    "# Define data paths (adjust these to your actual data location)\n",
    "data_dir = Path(\"../MEA-data\")  # Adjust path as needed\n",
    "\n",
    "# For this tutorial, we'll create synthetic data to demonstrate the workflow\n",
    "# In practice, you would load your actual .spk or .mat files\n",
    "\n",
    "def create_synthetic_mea_data(n_channels=64, duration=300.0, condition_name=\"synthetic\"):\n",
    "    \"\"\"\n",
    "    Create synthetic MEA data for demonstration purposes.\n",
    "    \n",
    "    This simulates realistic MEA recordings with bursts and network activity.\n",
    "    \"\"\"\n",
    "    np.random.seed(42 if condition_name == \"control\" else 123)\n",
    "    \n",
    "    spike_data = []\n",
    "    \n",
    "    # Different activity levels for different conditions\n",
    "    if condition_name == \"control\":\n",
    "        base_rate = 2.0  # Hz\n",
    "        burst_prob = 0.05\n",
    "    elif condition_name == \"treatment1\":\n",
    "        base_rate = 3.5  # Higher activity\n",
    "        burst_prob = 0.08\n",
    "    else:  # treatment2\n",
    "        base_rate = 1.5  # Lower activity\n",
    "        burst_prob = 0.03\n",
    "    \n",
    "    for ch in range(n_channels):\n",
    "        # Channel-specific activity level\n",
    "        channel_rate = base_rate * np.random.uniform(0.3, 2.0)\n",
    "        \n",
    "        # Generate background spikes\n",
    "        n_background_spikes = int(np.random.poisson(channel_rate * duration))\n",
    "        background_times = np.random.uniform(0, duration, n_background_spikes)\n",
    "        \n",
    "        # Add burst activity\n",
    "        burst_times = []\n",
    "        t = 0\n",
    "        while t < duration:\n",
    "            if np.random.random() < burst_prob:\n",
    "                # Create a burst\n",
    "                burst_start = t\n",
    "                burst_duration = np.random.uniform(0.1, 0.5)\n",
    "                n_burst_spikes = np.random.randint(5, 20)\n",
    "                \n",
    "                for _ in range(n_burst_spikes):\n",
    "                    spike_time = burst_start + np.random.exponential(0.02)\n",
    "                    if spike_time < burst_start + burst_duration:\n",
    "                        burst_times.append(spike_time)\n",
    "                \n",
    "                t += burst_duration + np.random.uniform(1.0, 3.0)\n",
    "            else:\n",
    "                t += np.random.uniform(0.1, 1.0)\n",
    "        \n",
    "        # Combine background and burst spikes\n",
    "        all_times = np.concatenate([background_times, burst_times])\n",
    "        all_times = all_times[all_times < duration]\n",
    "        \n",
    "        # Add to spike data list\n",
    "        for spike_time in all_times:\n",
    "            spike_data.append((ch, spike_time))\n",
    "    \n",
    "    return spike_data\n",
    "\n",
    "# Create synthetic data for three experimental conditions\n",
    "conditions = ['control', 'treatment1', 'treatment2']\n",
    "spike_lists = {}\n",
    "\n",
    "for condition in conditions:\n",
    "    print(f\"Creating synthetic data for condition: {condition}\")\n",
    "    \n",
    "    # Generate synthetic spike data\n",
    "    spike_data = create_synthetic_mea_data(\n",
    "        n_channels=64, \n",
    "        duration=300.0, \n",
    "        condition_name=condition\n",
    "    )\n",
    "    \n",
    "    # Create SpikeList object\n",
    "    spike_list = SpikeList(\n",
    "        spike_data=spike_data,\n",
    "        recording_length=300.0,\n",
    "        sampling_rate=12500.0\n",
    "    )\n",
    "    \n",
    "    spike_lists[condition] = spike_list\n",
    "    \n",
    "    print(f\"  - Channels: {len(spike_list.channel_ids)}\")\n",
    "    print(f\"  - Active channels: {len(spike_list.get_active_channels())}\")\n",
    "    print(f\"  - Total spikes: {sum(train.n_spikes for train in spike_list.spike_trains.values())}\")\n",
    "    print(f\"  - Recording length: {spike_list.recording_length:.1f} s\")\n",
    "    print()\n",
    "\n",
    "print(\"Data loading completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Data Exploration and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T18:16:43.578942Z",
     "iopub.status.busy": "2025-08-28T18:16:43.578799Z",
     "iopub.status.idle": "2025-08-28T18:16:43.593854Z",
     "shell.execute_reply": "2025-08-28T18:16:43.593433Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MEAPlotter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize plotter\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m plotter \u001b[38;5;241m=\u001b[39m \u001b[43mMEAPlotter\u001b[49m(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create raster plots for each condition\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m condition, spike_list \u001b[38;5;129;01min\u001b[39;00m spike_lists\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MEAPlotter' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize plotter\n",
    "plotter = MEAPlotter(figsize=(12, 8))\n",
    "\n",
    "# Create raster plots for each condition\n",
    "for condition, spike_list in spike_lists.items():\n",
    "    print(f\"Creating raster plot for {condition}...\")\n",
    "    \n",
    "    # Plot first 30 seconds of activity\n",
    "    fig = plotter.plot_raster(\n",
    "        spike_list,\n",
    "        time_range=(0, 30),\n",
    "        color_by_well=True\n",
    "    )\n",
    "    \n",
    "    plt.suptitle(f'Raster Plot - {condition.title()}')\n",
    "    plt.show()\n",
    "    \n",
    "    # Display summary statistics\n",
    "    summary_stats = spike_list.summary_statistics()\n",
    "    print(f\"\\nSummary for {condition}:\")\n",
    "    print(f\"  - Active channels: {len(spike_list.get_active_channels())}/{len(spike_list.channel_ids)}\")\n",
    "    print(f\"  - Mean firing rate: {summary_stats['firing_rate'].mean():.2f} ± {summary_stats['firing_rate'].std():.2f} Hz\")\n",
    "    print(f\"  - Total spikes: {summary_stats['n_spikes'].sum()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comprehensive Metrics Analysis\n",
    "\n",
    "Now we'll compute comprehensive metrics for all conditions including activity, regularity, and synchrony measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T18:16:43.595632Z",
     "iopub.status.busy": "2025-08-28T18:16:43.595509Z",
     "iopub.status.idle": "2025-08-28T18:16:43.609492Z",
     "shell.execute_reply": "2025-08-28T18:16:43.609187Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AnalysisConfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Configure analysis parameters\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mAnalysisConfig\u001b[49m(\n\u001b[1;32m      3\u001b[0m     time_bin_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[1;32m      4\u001b[0m     min_spikes_for_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      5\u001b[0m     n_pairs_sync\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,  \u001b[38;5;66;03m# Reduced for demo\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     burst_detection\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m     network_burst_detection\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Initialize metrics analyzer\u001b[39;00m\n\u001b[1;32m     11\u001b[0m metrics_analyzer \u001b[38;5;241m=\u001b[39m MEAMetrics(config\u001b[38;5;241m=\u001b[39mconfig)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AnalysisConfig' is not defined"
     ]
    }
   ],
   "source": [
    "# Configure analysis parameters\n",
    "config = AnalysisConfig(\n",
    "    time_bin_size=1.0,\n",
    "    min_spikes_for_rate=10,\n",
    "    n_pairs_sync=200,  # Reduced for demo\n",
    "    burst_detection=True,\n",
    "    network_burst_detection=True\n",
    ")\n",
    "\n",
    "# Initialize metrics analyzer\n",
    "metrics_analyzer = MEAMetrics(config=config)\n",
    "\n",
    "# Compute metrics for all conditions\n",
    "print(\"Computing comprehensive metrics for all conditions...\")\n",
    "all_metrics = metrics_analyzer.compare_conditions(\n",
    "    spike_lists, \n",
    "    grouping='global'\n",
    ")\n",
    "\n",
    "print(f\"\\nMetrics computed for {len(all_metrics)} condition(s)\")\n",
    "print(f\"Metrics calculated: {list(all_metrics.columns)}\")\n",
    "\n",
    "# Display key metrics\n",
    "key_metrics = [\n",
    "    'mean_firing_rate', 'network_firing_rate', 'active_channels_count',\n",
    "    'cv_isi_mean', 'pearson_cc_mean', 'network_burst_rate'\n",
    "]\n",
    "\n",
    "available_metrics = [m for m in key_metrics if m in all_metrics.columns]\n",
    "summary_table = all_metrics[['condition'] + available_metrics]\n",
    "\n",
    "print(\"\\n=== Key Metrics Summary ===\")\n",
    "print(summary_table.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Metrics Visualization and Statistical Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T18:16:43.611424Z",
     "iopub.status.busy": "2025-08-28T18:16:43.611296Z",
     "iopub.status.idle": "2025-08-28T18:16:43.630098Z",
     "shell.execute_reply": "2025-08-28T18:16:43.629755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating metrics comparison plots...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating metrics comparison plots...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Activity metrics comparison\u001b[39;00m\n\u001b[1;32m      5\u001b[0m activity_metrics \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 6\u001b[0m     col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[43mall_metrics\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns \n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(keyword \u001b[38;5;129;01min\u001b[39;00m col\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m keyword \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiring\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspike\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactive\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m col \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m ][:\u001b[38;5;241m6\u001b[39m]  \u001b[38;5;66;03m# Limit to 6 for clean visualization\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m activity_metrics:\n\u001b[1;32m     12\u001b[0m     fig \u001b[38;5;241m=\u001b[39m plotter\u001b[38;5;241m.\u001b[39mplot_metrics_comparison(\n\u001b[1;32m     13\u001b[0m         all_metrics,\n\u001b[1;32m     14\u001b[0m         grouping_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m         metrics_to_plot\u001b[38;5;241m=\u001b[39mactivity_metrics,\n\u001b[1;32m     16\u001b[0m         plot_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbox\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     17\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "# Create comprehensive metrics comparison plots\n",
    "print(\"Creating metrics comparison plots...\")\n",
    "\n",
    "# Activity metrics comparison\n",
    "activity_metrics = [\n",
    "    col for col in all_metrics.columns \n",
    "    if any(keyword in col.lower() for keyword in ['firing', 'rate', 'activity', 'spike', 'active'])\n",
    "    and col != 'condition'\n",
    "][:6]  # Limit to 6 for clean visualization\n",
    "\n",
    "if activity_metrics:\n",
    "    fig = plotter.plot_metrics_comparison(\n",
    "        all_metrics,\n",
    "        grouping_col='condition',\n",
    "        metrics_to_plot=activity_metrics,\n",
    "        plot_type='box'\n",
    "    )\n",
    "    plt.suptitle('Activity Metrics Comparison', fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "# Regularity metrics comparison\n",
    "regularity_metrics = [\n",
    "    col for col in all_metrics.columns \n",
    "    if any(keyword in col.lower() for keyword in ['cv', 'lv', 'entropy', 'regularity'])\n",
    "][:6]\n",
    "\n",
    "if regularity_metrics:\n",
    "    fig = plotter.plot_metrics_comparison(\n",
    "        all_metrics,\n",
    "        grouping_col='condition',\n",
    "        metrics_to_plot=regularity_metrics,\n",
    "        plot_type='violin'\n",
    "    )\n",
    "    plt.suptitle('Regularity Metrics Comparison', fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "# Synchrony metrics comparison\n",
    "synchrony_metrics = [\n",
    "    col for col in all_metrics.columns \n",
    "    if any(keyword in col.lower() for keyword in ['correlation', 'sync', 'distance', 'pearson'])\n",
    "][:4]\n",
    "\n",
    "if synchrony_metrics:\n",
    "    fig = plotter.plot_metrics_comparison(\n",
    "        all_metrics,\n",
    "        grouping_col='condition',\n",
    "        metrics_to_plot=synchrony_metrics,\n",
    "        plot_type='box'\n",
    "    )\n",
    "    plt.suptitle('Synchrony Metrics Comparison', fontsize=16, y=1.02)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Population Dynamics and Manifold Analysis\n",
    "\n",
    "Now we'll analyze the geometry of population dynamics using manifold learning techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T18:16:43.632768Z",
     "iopub.status.busy": "2025-08-28T18:16:43.632511Z",
     "iopub.status.idle": "2025-08-28T18:16:43.647930Z",
     "shell.execute_reply": "2025-08-28T18:16:43.647232Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ManifoldConfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Configure manifold analysis\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m manifold_config \u001b[38;5;241m=\u001b[39m \u001b[43mManifoldConfig\u001b[49m(\n\u001b[1;32m      3\u001b[0m     tau\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.02\u001b[39m,  \u001b[38;5;66;03m# Exponential filter time constant\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     dt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,  \u001b[38;5;66;03m# Sampling interval\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     max_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,  \u001b[38;5;66;03m# Limit for demo\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     methods\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPCA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUMAP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMDS\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Subset of methods for speed\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Initialize manifold analyzer\u001b[39;00m\n\u001b[1;32m     10\u001b[0m manifold_analyzer \u001b[38;5;241m=\u001b[39m ManifoldAnalysis(config\u001b[38;5;241m=\u001b[39mmanifold_config)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ManifoldConfig' is not defined"
     ]
    }
   ],
   "source": [
    "# Configure manifold analysis\n",
    "manifold_config = ManifoldConfig(\n",
    "    tau=0.02,  # Exponential filter time constant\n",
    "    dt=0.001,  # Sampling interval\n",
    "    max_components=10,  # Limit for demo\n",
    "    methods=['PCA', 'UMAP', 'MDS']  # Subset of methods for speed\n",
    ")\n",
    "\n",
    "# Initialize manifold analyzer\n",
    "manifold_analyzer = ManifoldAnalysis(config=manifold_config)\n",
    "\n",
    "print(\"Performing manifold analysis...\")\n",
    "print(\"This may take a few minutes for the full analysis...\")\n",
    "\n",
    "# Perform comparative manifold analysis\n",
    "manifold_results = manifold_analyzer.compare_conditions(\n",
    "    spike_lists,\n",
    "    time_range=(0, 60)  # Analyze first 60 seconds for speed\n",
    ")\n",
    "\n",
    "print(f\"\\nManifold analysis completed!\")\n",
    "print(f\"Analyzed conditions: {list(manifold_results['individual_results'].keys())}\")\n",
    "\n",
    "# Display effective dimensionalities\n",
    "print(\"\\n=== Effective Dimensionalities ===\")\n",
    "for condition, results in manifold_results['individual_results'].items():\n",
    "    eff_dim = results.get('effective_dimensionality', np.nan)\n",
    "    print(f\"{condition}: {eff_dim:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Manifold Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T18:16:43.650542Z",
     "iopub.status.busy": "2025-08-28T18:16:43.650310Z",
     "iopub.status.idle": "2025-08-28T18:16:43.676196Z",
     "shell.execute_reply": "2025-08-28T18:16:43.675568Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'manifold_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Visualize embeddings for each condition\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m condition, results \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmanifold_results\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindividual_results\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m results \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mVisualizing embeddings for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcondition\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'manifold_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualize embeddings for each condition\n",
    "for condition, results in manifold_results['individual_results'].items():\n",
    "    if 'embeddings' in results and len(results['embeddings']) > 0:\n",
    "        print(f\"\\nVisualizing embeddings for {condition}...\")\n",
    "        \n",
    "        embeddings = results['embeddings']\n",
    "        time_vector = results.get('time_vector', None)\n",
    "        \n",
    "        # Create embedding comparison plot\n",
    "        embedding_data = {}\n",
    "        for method, emb_result in embeddings.items():\n",
    "            if 'embedding' in emb_result:\n",
    "                embedding_data[method] = emb_result['embedding']\n",
    "        \n",
    "        if len(embedding_data) > 0:\n",
    "            fig = plotter.plot_manifold_comparison(\n",
    "                embedding_data,\n",
    "                labels=time_vector\n",
    "            )\n",
    "            plt.suptitle(f'Manifold Embeddings - {condition.title()}', fontsize=16)\n",
    "            plt.show()\n",
    "        \n",
    "        # Show PCA variance explained if available\n",
    "        if 'PCA' in embeddings and 'explained_variance_ratio' in embeddings['PCA']:\n",
    "            fig = plotter.plot_dimensionality_analysis(\n",
    "                embeddings['PCA']['explained_variance_ratio'],\n",
    "                method_name='PCA'\n",
    "            )\n",
    "            plt.suptitle(f'PCA Dimensionality Analysis - {condition.title()}', fontsize=14)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cross-Condition Analysis and Classification\n",
    "\n",
    "Let's examine how well we can distinguish between experimental conditions based on their neural dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T18:16:43.679258Z",
     "iopub.status.busy": "2025-08-28T18:16:43.678959Z",
     "iopub.status.idle": "2025-08-28T18:16:43.705426Z",
     "shell.execute_reply": "2025-08-28T18:16:43.705101Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'manifold_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Examine cross-condition comparison results\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomparison\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmanifold_results\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(manifold_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomparison\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      3\u001b[0m     comparison \u001b[38;5;241m=\u001b[39m manifold_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomparison\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== Cross-Condition Analysis Results ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'manifold_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Examine cross-condition comparison results\n",
    "if 'comparison' in manifold_results and len(manifold_results['comparison']) > 0:\n",
    "    comparison = manifold_results['comparison']\n",
    "    \n",
    "    print(\"=== Cross-Condition Analysis Results ===\")\n",
    "    \n",
    "    # Classification analysis\n",
    "    if 'classification_analysis' in comparison:\n",
    "        classification = comparison['classification_analysis']\n",
    "        \n",
    "        if 'classification_scores' in classification:\n",
    "            print(\"\\nClassification Accuracy (Cross-Validation):\")\n",
    "            \n",
    "            for method, classifiers in classification['classification_scores'].items():\n",
    "                print(f\"\\n{method}:\")\n",
    "                for clf_name, scores in classifiers.items():\n",
    "                    accuracy = scores.get('mean_accuracy', np.nan)\n",
    "                    std_acc = scores.get('std_accuracy', np.nan)\n",
    "                    print(f\"  {clf_name}: {accuracy:.3f} ± {std_acc:.3f}\")\n",
    "    \n",
    "    # Manifold alignment analysis\n",
    "    if 'manifold_alignment' in comparison:\n",
    "        alignment = comparison['manifold_alignment']\n",
    "        \n",
    "        if 'alignment_scores' in alignment:\n",
    "            print(\"\\n\\nManifold Alignment Scores:\")\n",
    "            \n",
    "            for method, alignments in alignment['alignment_scores'].items():\n",
    "                if alignments:\n",
    "                    print(f\"\\n{method}:\")\n",
    "                    for comparison_name, alignment_data in alignments.items():\n",
    "                        mse = alignment_data.get('procrustes_mse', np.nan)\n",
    "                        corr = alignment_data.get('mean_correlation', np.nan)\n",
    "                        print(f\"  {comparison_name}: MSE={mse:.4f}, Corr={corr:.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"Cross-condition comparison not available or failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Importance Analysis\n",
    "\n",
    "Identify which metrics are most discriminative between conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T18:16:43.708061Z",
     "iopub.status.busy": "2025-08-28T18:16:43.707934Z",
     "iopub.status.idle": "2025-08-28T18:16:43.711544Z",
     "shell.execute_reply": "2025-08-28T18:16:43.711038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance analysis failed: name 'manifold_results' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Analyze feature importance for discriminating conditions\n",
    "try:\n",
    "    from mea_flow.manifold.comparison import identify_discriminative_features\n",
    "    \n",
    "    # Extract individual condition results for feature analysis\n",
    "    individual_results = manifold_results.get('individual_results', {})\n",
    "    \n",
    "    if len(individual_results) >= 2:\n",
    "        print(\"Analyzing discriminative features...\")\n",
    "        \n",
    "        # Identify most important population statistics\n",
    "        feature_importance = identify_discriminative_features(\n",
    "            individual_results,\n",
    "            feature_type='population_statistics'\n",
    "        )\n",
    "        \n",
    "        if not feature_importance.empty:\n",
    "            print(\"\\n=== Most Discriminative Features ===\")\n",
    "            print(feature_importance.head(10))\n",
    "            \n",
    "            # Plot feature importance\n",
    "            if len(feature_importance) > 0:\n",
    "                fig = plotter.plot_feature_importance(\n",
    "                    feature_importance.head(10),\n",
    "                    top_n=10\n",
    "                )\n",
    "                plt.show()\n",
    "        else:\n",
    "            print(\"No discriminative features could be computed.\")\n",
    "    else:\n",
    "        print(\"Need at least 2 conditions for feature importance analysis.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Feature importance analysis failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Well-Based Analysis\n",
    "\n",
    "Analyze activity patterns at the individual well level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T18:16:43.713880Z",
     "iopub.status.busy": "2025-08-28T18:16:43.713724Z",
     "iopub.status.idle": "2025-08-28T18:16:43.730160Z",
     "shell.execute_reply": "2025-08-28T18:16:43.729665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing well-based analysis for control...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'metrics_analyzer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m spike_list \u001b[38;5;241m=\u001b[39m spike_lists[example_condition]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Compute metrics per well\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m well_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics_analyzer\u001b[49m\u001b[38;5;241m.\u001b[39mcompute_all_metrics(\n\u001b[1;32m     10\u001b[0m     spike_list,\n\u001b[1;32m     11\u001b[0m     grouping\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwell\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m well_metrics\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mWell-based metrics computed for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(well_metrics)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m wells\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics_analyzer' is not defined"
     ]
    }
   ],
   "source": [
    "# Perform well-based analysis for one condition\n",
    "example_condition = 'control'\n",
    "if example_condition in spike_lists:\n",
    "    print(f\"Performing well-based analysis for {example_condition}...\")\n",
    "    \n",
    "    spike_list = spike_lists[example_condition]\n",
    "    \n",
    "    # Compute metrics per well\n",
    "    well_metrics = metrics_analyzer.compute_all_metrics(\n",
    "        spike_list,\n",
    "        grouping='well'\n",
    "    )\n",
    "    \n",
    "    if not well_metrics.empty:\n",
    "        print(f\"\\nWell-based metrics computed for {len(well_metrics)} wells\")\n",
    "        print(well_metrics[['group_id', 'n_channels', 'mean_firing_rate', 'cv_isi_mean']].round(3))\n",
    "        \n",
    "        # Create well activity visualization\n",
    "        fig = plotter.plot_well_activity(\n",
    "            spike_list,\n",
    "            time_window=5.0\n",
    "        )\n",
    "        plt.show()\n",
    "        \n",
    "        # Create electrode map for the first well\n",
    "        fig = plotter.plot_electrode_map(\n",
    "            spike_list,\n",
    "            metric='firing_rate',\n",
    "            well_id=1\n",
    "        )\n",
    "        plt.show()\n",
    "    \n",
    "    else:\n",
    "        print(\"No well-based metrics could be computed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Time-Resolved Analysis\n",
    "\n",
    "Examine how metrics change over time within recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T18:16:43.732589Z",
     "iopub.status.busy": "2025-08-28T18:16:43.732346Z",
     "iopub.status.idle": "2025-08-28T18:16:43.752576Z",
     "shell.execute_reply": "2025-08-28T18:16:43.752127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing time-resolved analysis...\n",
      "\n",
      "Analyzing temporal dynamics for control...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'metrics_analyzer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAnalyzing temporal dynamics for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcondition\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Compute metrics over time windows\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m time_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics_analyzer\u001b[49m\u001b[38;5;241m.\u001b[39mcompute_all_metrics(\n\u001b[1;32m     11\u001b[0m     spike_list,\n\u001b[1;32m     12\u001b[0m     grouping\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m     group_params\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwindow_length\u001b[39m\u001b[38;5;124m'\u001b[39m: time_window_length}\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m time_metrics\u001b[38;5;241m.\u001b[39mempty \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(time_metrics) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Computed metrics for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(time_metrics)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m time windows\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics_analyzer' is not defined"
     ]
    }
   ],
   "source": [
    "# Perform time-resolved analysis\n",
    "print(\"Performing time-resolved analysis...\")\n",
    "\n",
    "time_window_length = 30.0  # 30-second windows\n",
    "\n",
    "for condition, spike_list in spike_lists.items():\n",
    "    print(f\"\\nAnalyzing temporal dynamics for {condition}...\")\n",
    "    \n",
    "    # Compute metrics over time windows\n",
    "    time_metrics = metrics_analyzer.compute_all_metrics(\n",
    "        spike_list,\n",
    "        grouping='time',\n",
    "        group_params={'window_length': time_window_length}\n",
    "    )\n",
    "    \n",
    "    if not time_metrics.empty and len(time_metrics) > 2:\n",
    "        print(f\"  Computed metrics for {len(time_metrics)} time windows\")\n",
    "        \n",
    "        # Plot temporal evolution of key metrics\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        metrics_to_plot = ['mean_firing_rate', 'cv_isi_mean', 'pearson_cc_mean', 'active_channels_count']\n",
    "        \n",
    "        for i, metric in enumerate(metrics_to_plot):\n",
    "            if metric in time_metrics.columns:\n",
    "                ax = axes[i]\n",
    "                \n",
    "                time_points = time_metrics['window_start'] + time_window_length/2\n",
    "                values = time_metrics[metric]\n",
    "                \n",
    "                ax.plot(time_points, values, 'o-', linewidth=2, markersize=6)\n",
    "                ax.set_xlabel('Time (s)')\n",
    "                ax.set_ylabel(metric.replace('_', ' ').title())\n",
    "                ax.grid(True, alpha=0.3)\n",
    "                ax.set_title(f'{metric.replace(\"_\", \" \").title()} Over Time')\n",
    "        \n",
    "        plt.suptitle(f'Temporal Dynamics - {condition.title()}', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    else:\n",
    "        print(f\"  Insufficient data for temporal analysis in {condition}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary and Results Export\n",
    "\n",
    "Summarize the key findings and demonstrate how to export results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T18:16:43.754217Z",
     "iopub.status.busy": "2025-08-28T18:16:43.754076Z",
     "iopub.status.idle": "2025-08-28T18:16:43.779128Z",
     "shell.execute_reply": "2025-08-28T18:16:43.778742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MEA-Flow Analysis Summary ===\n",
      "\n",
      "Analyzed Conditions: ['control', 'treatment1', 'treatment2']\n",
      "Recording Duration: 300.0 seconds\n",
      "Total Channels: 64\n",
      "\n",
      "=== Condition Summary ===\n",
      "    Condition  Active_Channels  Total_Spikes  Mean_Rate_Hz\n",
      "0     control               64         62718          3.27\n",
      "1  treatment1               64         95075          4.95\n",
      "2  treatment2               64         43189          2.25\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(summary_df\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Key findings from metrics\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mall_metrics\u001b[49m\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Key Metric Differences ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_firing_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcv_isi_mean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpearson_cc_mean\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "# Create comprehensive summary\n",
    "print(\"=== MEA-Flow Analysis Summary ===\")\n",
    "print(f\"\\nAnalyzed Conditions: {list(spike_lists.keys())}\")\n",
    "print(f\"Recording Duration: {list(spike_lists.values())[0].recording_length} seconds\")\n",
    "print(f\"Total Channels: {len(list(spike_lists.values())[0].channel_ids)}\")\n",
    "\n",
    "# Summary statistics table\n",
    "summary_stats = []\n",
    "for condition, spike_list in spike_lists.items():\n",
    "    stats = {\n",
    "        'Condition': condition,\n",
    "        'Active_Channels': len(spike_list.get_active_channels()),\n",
    "        'Total_Spikes': sum(train.n_spikes for train in spike_list.spike_trains.values()),\n",
    "        'Mean_Rate_Hz': np.mean([train.firing_rate for train in spike_list.spike_trains.values() if train.n_spikes > 0])\n",
    "    }\n",
    "    summary_stats.append(stats)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_stats)\n",
    "print(\"\\n=== Condition Summary ===\")\n",
    "print(summary_df.round(2))\n",
    "\n",
    "# Key findings from metrics\n",
    "if not all_metrics.empty:\n",
    "    print(\"\\n=== Key Metric Differences ===\")\n",
    "    \n",
    "    for metric in ['mean_firing_rate', 'cv_isi_mean', 'pearson_cc_mean']:\n",
    "        if metric in all_metrics.columns:\n",
    "            values = all_metrics.groupby('condition')[metric].mean()\n",
    "            print(f\"\\n{metric.replace('_', ' ').title()}:\")\n",
    "            for condition, value in values.items():\n",
    "                print(f\"  {condition}: {value:.4f}\")\n",
    "\n",
    "print(\"\\n=== Export Results ===\")\n",
    "\n",
    "# Demonstrate saving results\n",
    "try:\n",
    "    from mea_flow.utils.io import save_results, export_to_format\n",
    "    \n",
    "    # Create results directory\n",
    "    results_dir = Path(\"./mea_flow_results\")\n",
    "    results_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Export metrics to CSV\n",
    "    if not all_metrics.empty:\n",
    "        export_to_format(\n",
    "            all_metrics,\n",
    "            results_dir / \"metrics_summary.csv\",\n",
    "            format='csv'\n",
    "        )\n",
    "        print(\"✓ Metrics exported to metrics_summary.csv\")\n",
    "    \n",
    "    # Save complete results\n",
    "    complete_results = {\n",
    "        'metrics': all_metrics,\n",
    "        'manifold_results': manifold_results,\n",
    "        'summary_statistics': summary_df,\n",
    "        'analysis_config': config.__dict__,\n",
    "        'conditions_analyzed': list(spike_lists.keys())\n",
    "    }\n",
    "    \n",
    "    save_results(\n",
    "        complete_results,\n",
    "        results_dir / \"complete_analysis.pkl\"\n",
    "    )\n",
    "    print(\"✓ Complete results saved to complete_analysis.pkl\")\n",
    "    \n",
    "    print(f\"\\nAll results saved to: {results_dir.absolute()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Export failed: {e}\")\n",
    "\n",
    "print(\"\\n🎉 MEA-Flow Tutorial Completed Successfully! 🎉\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Next Steps and Advanced Usage\n",
    "\n",
    "This tutorial covered the basic workflow of MEA-Flow. Here are some directions for further analysis:\n",
    "\n",
    "### Advanced Analysis Options:\n",
    "\n",
    "1. **Custom Parameter Sets**: Use `get_analysis_presets()` for specialized analysis types\n",
    "2. **Detailed Manifold Analysis**: Explore additional dimensionality reduction methods\n",
    "3. **Network Burst Analysis**: Examine burst dynamics in detail\n",
    "4. **Cross-Temporal Analysis**: Compare dynamics across different time periods\n",
    "5. **Multi-Scale Analysis**: Analyze at different temporal resolutions\n",
    "\n",
    "### Loading Real Data:\n",
    "\n",
    "```python\n",
    "# Load Axion .spk files (after MATLAB conversion)\n",
    "spike_list = load_data('path/to/data.mat', \n",
    "                     channels_key='Channels',\n",
    "                     times_key='Times')\n",
    "\n",
    "# Load multiple files\n",
    "file_paths = ['condition1.mat', 'condition2.mat', 'condition3.mat']\n",
    "condition_names = ['Control', 'Treatment1', 'Treatment2']\n",
    "spike_lists = load_multiple_files(file_paths, condition_names)\n",
    "```\n",
    "\n",
    "### Statistical Analysis:\n",
    "\n",
    "For rigorous statistical comparisons, consider:\n",
    "- Multiple comparison corrections\n",
    "- Non-parametric tests for non-normal distributions\n",
    "- Effect size calculations\n",
    "- Bootstrap confidence intervals\n",
    "\n",
    "### Performance Optimization:\n",
    "\n",
    "For large datasets:\n",
    "- Use time windowing to reduce computational load\n",
    "- Limit the number of manifold learning methods\n",
    "- Reduce the number of pairs for synchrony analysis\n",
    "- Use parallel processing where available\n",
    "\n",
    "Refer to the MEA-Flow documentation for detailed API reference and additional examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
