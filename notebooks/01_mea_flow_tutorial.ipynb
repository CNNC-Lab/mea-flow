{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MEA-Flow Tutorial: Basic Analysis Workflow\n",
        "\n",
        "This notebook demonstrates the basic MEA-Flow workflow for analyzing multi-electrode array data.\n",
        "\n",
        "## Overview\n",
        "\n",
        "MEA-Flow provides tools for:\n",
        "1. **Data Loading**: Support for MEA data formats\n",
        "2. **Metrics Calculation**: Activity and synchrony measures\n",
        "3. **Visualization**: Raster plots and comparisons\n",
        "4. **Analysis**: Cross-condition comparisons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# MEA-Flow imports\n",
        "from mea_flow import SpikeList, MEAMetrics\n",
        "from mea_flow.analysis.metrics import AnalysisConfig\n",
        "\n",
        "# Set up matplotlib\n",
        "plt.style.use(\"default\")\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"MEA-Flow Tutorial - Ready to begin!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Creation\n",
        "\n",
        "We'll create synthetic MEA data to demonstrate the workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create synthetic MEA data for demonstration\n",
        "def create_synthetic_mea_data(condition_name=\"control\", n_channels=16, duration=60.0):\n",
        "    \"\"\"Create synthetic MEA data for demonstration.\"\"\"\n",
        "    np.random.seed(42 if condition_name == \"control\" else 123 if condition_name == \"treatment1\" else 456)\n",
        "    \n",
        "    # Different activity levels for different conditions\n",
        "    if condition_name == \"control\":\n",
        "        base_rate = 2.0  # Hz\n",
        "    elif condition_name == \"treatment1\":\n",
        "        base_rate = 3.5  # Higher activity\n",
        "    else:  # treatment2\n",
        "        base_rate = 1.5  # Lower activity\n",
        "    \n",
        "    spike_data = {}\n",
        "    \n",
        "    for ch in range(n_channels):\n",
        "        # Generate spikes for this channel - ensure minimum activity\n",
        "        channel_rate = base_rate * np.random.uniform(0.8, 1.5)\n",
        "        n_spikes = max(10, int(np.random.poisson(channel_rate * duration)))  # Ensure min 10 spikes\n",
        "        spike_times = np.sort(np.random.uniform(0, duration, n_spikes))\n",
        "        spike_data[ch] = spike_times\n",
        "    \n",
        "    return spike_data\n",
        "\n",
        "# Create synthetic data for three experimental conditions\n",
        "conditions = [\"control\", \"treatment1\", \"treatment2\"]\n",
        "spike_lists = {}\n",
        "\n",
        "for condition in conditions:\n",
        "    print(f\"Creating synthetic data for condition: {condition}\")\n",
        "    \n",
        "    # Generate synthetic spike data\n",
        "    spike_data = create_synthetic_mea_data(\n",
        "        condition_name=condition,\n",
        "        n_channels=16,\n",
        "        duration=60.0\n",
        "    )\n",
        "    \n",
        "    # Create SpikeList object\n",
        "    spike_list = SpikeList(\n",
        "        spike_data=spike_data,\n",
        "        recording_length=60.0\n",
        "    )\n",
        "    \n",
        "    spike_lists[condition] = spike_list\n",
        "    \n",
        "    print(f\"  - Channels: {len(spike_list.channel_ids)}\")\n",
        "    print(f\"  - Active channels: {len(spike_list.get_active_channels())}\")\n",
        "    print(f\"  - Total spikes: {sum(train.n_spikes for train in spike_list.spike_trains.values())}\")\n",
        "    print(f\"  - Recording length: {spike_list.recording_length:.1f} s\")\n",
        "    print()\n",
        "\n",
        "print(\"Data loading completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Basic Visualization\n",
        "\n",
        "Create raster plots to visualize spike activity patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create raster plots for each condition\n",
        "for condition, spike_list in spike_lists.items():\n",
        "    print(f\"Creating raster plot for {condition}...\")\n",
        "    \n",
        "    # Plot first 20 seconds of activity\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    \n",
        "    # Simple raster plot\n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, 16))\n",
        "    for i, ch_id in enumerate(spike_list.get_active_channels()[:8]):  # Show first 8 channels\n",
        "        spike_times = spike_list.spike_trains[ch_id].spike_times\n",
        "        spike_times = spike_times[spike_times <= 20]  # First 20 seconds\n",
        "        ax.scatter(spike_times, [ch_id] * len(spike_times), s=2, alpha=0.8, color=colors[i])\n",
        "    \n",
        "    ax.set_xlabel(\"Time (s)\")\n",
        "    ax.set_ylabel(\"Channel ID\")\n",
        "    ax.set_title(f\"Raster Plot - {condition.title()}\")\n",
        "    ax.set_xlim(0, 20)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Display summary statistics\n",
        "    active_channels = spike_list.get_active_channels()\n",
        "    firing_rates = [spike_list.spike_trains[ch].firing_rate for ch in active_channels]\n",
        "    total_spikes = sum(spike_list.spike_trains[ch].n_spikes for ch in active_channels)\n",
        "    \n",
        "    print(f\"\\nSummary for {condition}:\")\n",
        "    print(f\"  - Active channels: {len(active_channels)}/{len(spike_list.channel_ids)}\")\n",
        "    print(f\"  - Mean firing rate: {np.mean(firing_rates):.2f} \u00b1 {np.std(firing_rates):.2f} Hz\")\n",
        "    print(f\"  - Total spikes: {total_spikes}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Metrics Analysis\n",
        "\n",
        "Compute comprehensive metrics for each condition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute metrics for all conditions\n",
        "print(\"Computing comprehensive metrics for all conditions...\")\n",
        "\n",
        "# Initialize metrics analyzer\n",
        "config = AnalysisConfig(\n",
        "    time_bin_size=1.0,\n",
        "    min_spikes_for_rate=5,\n",
        "    burst_detection=False,  # Disable for simplicity\n",
        "    network_burst_detection=False,\n",
        "    n_pairs_sync=50  # Reduce for faster computation\n",
        ")\n",
        "\n",
        "metrics_analyzer = MEAMetrics(config=config)\n",
        "\n",
        "# Compute all metrics for each condition\n",
        "all_metrics = []\n",
        "\n",
        "for condition, spike_list in spike_lists.items():\n",
        "    print(f\"Computing metrics for {condition}...\")\n",
        "    \n",
        "    # Compute all metrics\n",
        "    metrics_df = metrics_analyzer.compute_all_metrics(spike_list, grouping=\"global\")\n",
        "    \n",
        "    # Add condition info\n",
        "    metrics_df[\"condition\"] = condition\n",
        "    all_metrics.append(metrics_df)\n",
        "\n",
        "# Combine all metrics\n",
        "all_metrics_df = pd.concat(all_metrics, ignore_index=True)\n",
        "\n",
        "print(f\"\\nMetrics computed for {len(all_metrics_df)} condition(s)\")\n",
        "\n",
        "# Display key metrics\n",
        "key_metrics = [\n",
        "    \"condition\", \"activity_mean_firing_rate\", \"activity_active_channels_count\",\n",
        "    \"activity_network_firing_rate\", \"regularity_cv_isi_mean\", \"synchrony_pearson_cc_mean\"\n",
        "]\n",
        "available_metrics = [col for col in key_metrics if col in all_metrics_df.columns]\n",
        "\n",
        "print(\"\\n=== Key Metrics Summary ===\")\n",
        "print(all_metrics_df[available_metrics].round(4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Metrics Comparison\n",
        "\n",
        "Visualize differences between conditions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive metrics comparison plots\n",
        "print(\"Creating metrics comparison plots...\")\n",
        "\n",
        "# Create subplots for multiple metrics\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "conditions = all_metrics_df[\"condition\"].values\n",
        "colors = [\"skyblue\", \"orange\", \"lightgreen\"]\n",
        "\n",
        "# Plot 1: Mean Firing Rate\n",
        "if \"activity_mean_firing_rate\" in all_metrics_df.columns:\n",
        "    firing_rates = all_metrics_df[\"activity_mean_firing_rate\"].values\n",
        "    bars1 = axes[0].bar(conditions, firing_rates, alpha=0.7, color=colors)\n",
        "    axes[0].set_ylabel(\"Mean Firing Rate (Hz)\")\n",
        "    axes[0].set_title(\"Mean Firing Rate by Condition\")\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    for bar, rate in zip(bars1, firing_rates):\n",
        "        if not np.isnan(rate):\n",
        "            axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
        "                        f\"{rate:.2f}\", ha=\"center\", va=\"bottom\")\n",
        "\n",
        "# Plot 2: Active Channels\n",
        "if \"activity_active_channels_count\" in all_metrics_df.columns:\n",
        "    active_channels = all_metrics_df[\"activity_active_channels_count\"].values\n",
        "    bars2 = axes[1].bar(conditions, active_channels, alpha=0.7, color=colors)\n",
        "    axes[1].set_ylabel(\"Active Channels Count\")\n",
        "    axes[1].set_title(\"Active Channels by Condition\")\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    for bar, count in zip(bars2, active_channels):\n",
        "        if not np.isnan(count):\n",
        "            axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
        "                        f\"{int(count)}\", ha=\"center\", va=\"bottom\")\n",
        "\n",
        "# Plot 3: CV ISI (Regularity)\n",
        "if \"regularity_cv_isi_mean\" in all_metrics_df.columns:\n",
        "    cv_isi = all_metrics_df[\"regularity_cv_isi_mean\"].values\n",
        "    bars3 = axes[2].bar(conditions, cv_isi, alpha=0.7, color=colors)\n",
        "    axes[2].set_ylabel(\"CV ISI (Irregularity)\")\n",
        "    axes[2].set_title(\"Spike Regularity by Condition\")\n",
        "    axes[2].grid(True, alpha=0.3)\n",
        "    for bar, cv in zip(bars3, cv_isi):\n",
        "        if not np.isnan(cv):\n",
        "            axes[2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
        "                        f\"{cv:.2f}\", ha=\"center\", va=\"bottom\")\n",
        "\n",
        "# Plot 4: Synchrony\n",
        "if \"synchrony_pearson_cc_mean\" in all_metrics_df.columns:\n",
        "    synchrony = all_metrics_df[\"synchrony_pearson_cc_mean\"].values\n",
        "    bars4 = axes[3].bar(conditions, synchrony, alpha=0.7, color=colors)\n",
        "    axes[3].set_ylabel(\"Mean Correlation\")\n",
        "    axes[3].set_title(\"Network Synchrony by Condition\")\n",
        "    axes[3].grid(True, alpha=0.3)\n",
        "    for bar, sync in zip(bars4, synchrony):\n",
        "        if not np.isnan(sync):\n",
        "            axes[3].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.002,\n",
        "                        f\"{sync:.3f}\", ha=\"center\", va=\"bottom\")\n",
        "\n",
        "# Rotate x-axis labels\n",
        "for ax in axes:\n",
        "    ax.tick_params(axis=\"x\", rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print numerical comparison\n",
        "print(\"\\n=== Detailed Numerical Comparison ===\")\n",
        "for i, condition in enumerate(conditions):\n",
        "    print(f\"\\n{condition.upper()}:\")\n",
        "    if \"activity_mean_firing_rate\" in all_metrics_df.columns:\n",
        "        print(f\"  - Firing rate: {all_metrics_df.iloc[i][\"activity_mean_firing_rate\"]:.2f} Hz\")\n",
        "    if \"activity_active_channels_count\" in all_metrics_df.columns:\n",
        "        print(f\"  - Active channels: {int(all_metrics_df.iloc[i][\"activity_active_channels_count\"])}\")\n",
        "    if \"regularity_cv_isi_mean\" in all_metrics_df.columns:\n",
        "        cv_val = all_metrics_df.iloc[i][\"regularity_cv_isi_mean\"]\n",
        "        print(f\"  - Spike regularity (CV ISI): {cv_val:.3f}\" if not np.isnan(cv_val) else \"  - Spike regularity: N/A\")\n",
        "    if \"synchrony_pearson_cc_mean\" in all_metrics_df.columns:\n",
        "        sync_val = all_metrics_df.iloc[i][\"synchrony_pearson_cc_mean\"]\n",
        "        print(f\"  - Network synchrony: {sync_val:.3f}\" if not np.isnan(sync_val) else \"  - Network synchrony: N/A\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This tutorial demonstrated the basic MEA-Flow workflow:\n",
        "\n",
        "1. **Data Loading**: Created synthetic MEA data for multiple conditions\n",
        "2. **Visualization**: Generated raster plots to visualize spike activity\n",
        "3. **Metrics Analysis**: Computed comprehensive metrics (activity, regularity, synchrony)\n",
        "4. **Comparison**: Compared metrics across experimental conditions\n",
        "\n",
        "### Key Results:\n",
        "- Successfully loaded and processed multi-condition MEA data\n",
        "- Computed comprehensive activity, regularity, and synchrony metrics\n",
        "- Visualized clear differences between treatment conditions\n",
        "- Demonstrated the full MEA-Flow analysis pipeline\n",
        "\n",
        "### Next Steps:\n",
        "- Load real .spk or .mat files using \n",
        "- Explore burst detection and network burst analysis\n",
        "- Perform manifold analysis for population dynamics\n",
        "- Use statistical tests for rigorous condition comparisons\n",
        "- Analyze time-resolved dynamics\n",
        "\n",
        "For more advanced analysis, explore the other example scripts and notebooks in the MEA-Flow package."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}