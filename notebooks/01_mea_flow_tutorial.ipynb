{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEA-Flow Tutorial: Comprehensive Analysis of Multi-Electrode Array Data\n",
    "\n",
    "This notebook demonstrates the complete workflow for analyzing MEA data using the MEA-Flow library, focusing on neural population dynamics and comparative analysis across experimental conditions.\n",
    "\n",
    "## Overview\n",
    "\n",
    "MEA-Flow provides a comprehensive pipeline for:\n",
    "1. **Data Loading**: Support for various MEA data formats (.spk, .mat, CSV)\n",
    "2. **Metrics Calculation**: Activity, regularity, and synchrony measures\n",
    "3. **Manifold Analysis**: Population geometry and dimensionality reduction\n",
    "4. **Visualization**: Publication-ready plots and visualizations\n",
    "5. **Comparative Analysis**: Cross-condition statistical comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# MEA-Flow imports\n",
    "from mea_flow import (\n",
    "    # Data loading and processing\n",
    "    SpikeList, load_data, load_multiple_files,\n",
    "    \n",
    "    # Analysis modules\n",
    "    MEAMetrics, ManifoldAnalysis,\n",
    "    \n",
    "    # Visualization\n",
    "    MEAPlotter,\n",
    ")\n",
    "\n",
    "from mea_flow.analysis import AnalysisConfig\n",
    "from mea_flow.manifold import ManifoldConfig\n",
    "from mea_flow.utils import get_default_parameters, setup_logging\n",
    "\n",
    "# Set up logging\n",
    "logger = setup_logging('INFO')\n",
    "\n",
    "print(\"MEA-Flow Tutorial - Ready to begin!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Initial Exploration\n",
    "\n",
    "We'll demonstrate loading MEA data from different formats and explore the basic structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths (adjust these to your actual data location)\n",
    "data_dir = Path(\"../MEA-data\")  # Adjust path as needed\n",
    "\n",
    "# For this tutorial, we'll create synthetic data to demonstrate the workflow\n",
    "# In practice, you would load your actual .spk or .mat files\n",
    "\n",
    "def create_synthetic_mea_data(n_channels=64, duration=300.0, condition_name=\"synthetic\"):\n",
    "    \"\"\"\n",
    "    Create synthetic MEA data for demonstration purposes.\n",
    "    \n",
    "    This simulates realistic MEA recordings with bursts and network activity.\n",
    "    \"\"\"\n",
    "    np.random.seed(42 if condition_name == \"control\" else 123)\n",
    "    \n",
    "    spike_data = []\n",
    "    \n",
    "    # Different activity levels for different conditions\n",
    "    if condition_name == \"control\":\n",
    "        base_rate = 2.0  # Hz\n",
    "        burst_prob = 0.05\n",
    "    elif condition_name == \"treatment1\":\n",
    "        base_rate = 3.5  # Higher activity\n",
    "        burst_prob = 0.08\n",
    "    else:  # treatment2\n",
    "        base_rate = 1.5  # Lower activity\n",
    "        burst_prob = 0.03\n",
    "    \n",
    "    for ch in range(n_channels):\n",
    "        # Channel-specific activity level\n",
    "        channel_rate = base_rate * np.random.uniform(0.3, 2.0)\n",
    "        \n",
    "        # Generate background spikes\n",
    "        n_background_spikes = int(np.random.poisson(channel_rate * duration))\n",
    "        background_times = np.random.uniform(0, duration, n_background_spikes)\n",
    "        \n",
    "        # Add burst activity\n",
    "        burst_times = []\n",
    "        t = 0\n",
    "        while t < duration:\n",
    "            if np.random.random() < burst_prob:\n",
    "                # Create a burst\n",
    "                burst_start = t\n",
    "                burst_duration = np.random.uniform(0.1, 0.5)\n",
    "                n_burst_spikes = np.random.randint(5, 20)\n",
    "                \n",
    "                for _ in range(n_burst_spikes):\n",
    "                    spike_time = burst_start + np.random.exponential(0.02)\n",
    "                    if spike_time < burst_start + burst_duration:\n",
    "                        burst_times.append(spike_time)\n",
    "                \n",
    "                t += burst_duration + np.random.uniform(1.0, 3.0)\n",
    "            else:\n",
    "                t += np.random.uniform(0.1, 1.0)\n",
    "        \n",
    "        # Combine background and burst spikes\n",
    "        all_times = np.concatenate([background_times, burst_times])\n",
    "        all_times = all_times[all_times < duration]\n",
    "        \n",
    "        # Add to spike data list\n",
    "        for spike_time in all_times:\n",
    "            spike_data.append((ch, spike_time))\n",
    "    \n",
    "    return spike_data\n",
    "\n",
    "# Create synthetic data for three experimental conditions\n",
    "conditions = ['control', 'treatment1', 'treatment2']\n",
    "spike_lists = {}\n",
    "\n",
    "for condition in conditions:\n",
    "    print(f\"Creating synthetic data for condition: {condition}\")\n",
    "    \n",
    "    # Generate synthetic spike data\n",
    "    spike_data = create_synthetic_mea_data(\n",
    "        n_channels=64, \n",
    "        duration=300.0, \n",
    "        condition_name=condition\n",
    "    )\n",
    "    \n",
    "    # Create SpikeList object\n",
    "    spike_list = SpikeList(\n",
    "        spike_data=spike_data,\n",
    "        recording_length=300.0,\n",
    "        sampling_rate=12500.0\n",
    "    )\n",
    "    \n",
    "    spike_lists[condition] = spike_list\n",
    "    \n",
    "    print(f\"  - Channels: {len(spike_list.channel_ids)}\")\n",
    "    print(f\"  - Active channels: {len(spike_list.get_active_channels())}\")\n",
    "    print(f\"  - Total spikes: {sum(train.n_spikes for train in spike_list.spike_trains.values())}\")\n",
    "    print(f\"  - Recording length: {spike_list.recording_length:.1f} s\")\n",
    "    print()\n",
    "\n",
    "print(\"Data loading completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Data Exploration and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize plotter\n",
    "plotter = MEAPlotter(figsize=(12, 8))\n",
    "\n",
    "# Create raster plots for each condition\n",
    "for condition, spike_list in spike_lists.items():\n",
    "    print(f\"Creating raster plot for {condition}...\")\n",
    "    \n",
    "    # Plot first 30 seconds of activity\n",
    "    fig = plotter.plot_raster(\n",
    "        spike_list,\n",
    "        time_range=(0, 30),\n",
    "        color_by_well=True\n",
    "    )\n",
    "    \n",
    "    plt.suptitle(f'Raster Plot - {condition.title()}')\n",
    "    plt.show()\n",
    "    \n",
    "    # Display summary statistics\n",
    "    summary_stats = spike_list.summary_statistics()\n",
    "    print(f\"\\nSummary for {condition}:\")\n",
    "    print(f\"  - Active channels: {len(spike_list.get_active_channels())}/{len(spike_list.channel_ids)}\")\n",
    "    print(f\"  - Mean firing rate: {summary_stats['firing_rate'].mean():.2f} Â± {summary_stats['firing_rate'].std():.2f} Hz\")\n",
    "    print(f\"  - Total spikes: {summary_stats['n_spikes'].sum()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comprehensive Metrics Analysis\n",
    "\n",
    "Now we'll compute comprehensive metrics for all conditions including activity, regularity, and synchrony measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure analysis parameters\n",
    "config = AnalysisConfig(\n",
    "    time_bin_size=1.0,\n",
    "    min_spikes_for_rate=10,\n",
    "    n_pairs_sync=200,  # Reduced for demo\n",
    "    burst_detection=True,\n",
    "    network_burst_detection=True\n",
    ")\n",
    "\n",
    "# Initialize metrics analyzer\n",
    "metrics_analyzer = MEAMetrics(config=config)\n",
    "\n",
    "# Compute metrics for all conditions\n",
    "print(\"Computing comprehensive metrics for all conditions...\")\n",
    "all_metrics = metrics_analyzer.compare_conditions(\n",
    "    spike_lists, \n",
    "    grouping='global'\n",
    ")\n",
    "\n",
    "print(f\"\\nMetrics computed for {len(all_metrics)} condition(s)\")\n",
    "print(f\"Metrics calculated: {list(all_metrics.columns)}\")\n",
    "\n",
    "# Display key metrics\n",
    "key_metrics = [\n",
    "    'mean_firing_rate', 'network_firing_rate', 'active_channels_count',\n",
    "    'cv_isi_mean', 'pearson_cc_mean', 'network_burst_rate'\n",
    "]\n",
    "\n",
    "available_metrics = [m for m in key_metrics if m in all_metrics.columns]\n",
    "summary_table = all_metrics[['condition'] + available_metrics]\n",
    "\n",
    "print(\"\\n=== Key Metrics Summary ===\")\n",
    "print(summary_table.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Metrics Visualization and Statistical Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive metrics comparison plots\n",
    "print(\"Creating metrics comparison plots...\")\n",
    "\n",
    "# Activity metrics comparison\n",
    "activity_metrics = [\n",
    "    col for col in all_metrics.columns \n",
    "    if any(keyword in col.lower() for keyword in ['firing', 'rate', 'activity', 'spike', 'active'])\n",
    "    and col != 'condition'\n",
    "][:6]  # Limit to 6 for clean visualization\n",
    "\n",
    "if activity_metrics:\n",
    "    fig = plotter.plot_metrics_comparison(\n",
    "        all_metrics,\n",
    "        grouping_col='condition',\n",
    "        metrics_to_plot=activity_metrics,\n",
    "        plot_type='box'\n",
    "    )\n",
    "    plt.suptitle('Activity Metrics Comparison', fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "# Regularity metrics comparison\n",
    "regularity_metrics = [\n",
    "    col for col in all_metrics.columns \n",
    "    if any(keyword in col.lower() for keyword in ['cv', 'lv', 'entropy', 'regularity'])\n",
    "][:6]\n",
    "\n",
    "if regularity_metrics:\n",
    "    fig = plotter.plot_metrics_comparison(\n",
    "        all_metrics,\n",
    "        grouping_col='condition',\n",
    "        metrics_to_plot=regularity_metrics,\n",
    "        plot_type='violin'\n",
    "    )\n",
    "    plt.suptitle('Regularity Metrics Comparison', fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "# Synchrony metrics comparison\n",
    "synchrony_metrics = [\n",
    "    col for col in all_metrics.columns \n",
    "    if any(keyword in col.lower() for keyword in ['correlation', 'sync', 'distance', 'pearson'])\n",
    "][:4]\n",
    "\n",
    "if synchrony_metrics:\n",
    "    fig = plotter.plot_metrics_comparison(\n",
    "        all_metrics,\n",
    "        grouping_col='condition',\n",
    "        metrics_to_plot=synchrony_metrics,\n",
    "        plot_type='box'\n",
    "    )\n",
    "    plt.suptitle('Synchrony Metrics Comparison', fontsize=16, y=1.02)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Population Dynamics and Manifold Analysis\n",
    "\n",
    "Now we'll analyze the geometry of population dynamics using manifold learning techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure manifold analysis\n",
    "manifold_config = ManifoldConfig(\n",
    "    tau=0.02,  # Exponential filter time constant\n",
    "    dt=0.001,  # Sampling interval\n",
    "    max_components=10,  # Limit for demo\n",
    "    methods=['PCA', 'UMAP', 'MDS']  # Subset of methods for speed\n",
    ")\n",
    "\n",
    "# Initialize manifold analyzer\n",
    "manifold_analyzer = ManifoldAnalysis(config=manifold_config)\n",
    "\n",
    "print(\"Performing manifold analysis...\")\n",
    "print(\"This may take a few minutes for the full analysis...\")\n",
    "\n",
    "# Perform comparative manifold analysis\n",
    "manifold_results = manifold_analyzer.compare_conditions(\n",
    "    spike_lists,\n",
    "    time_range=(0, 60)  # Analyze first 60 seconds for speed\n",
    ")\n",
    "\n",
    "print(f\"\\nManifold analysis completed!\")\n",
    "print(f\"Analyzed conditions: {list(manifold_results['individual_results'].keys())}\")\n",
    "\n",
    "# Display effective dimensionalities\n",
    "print(\"\\n=== Effective Dimensionalities ===\")\n",
    "for condition, results in manifold_results['individual_results'].items():\n",
    "    eff_dim = results.get('effective_dimensionality', np.nan)\n",
    "    print(f\"{condition}: {eff_dim:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Manifold Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embeddings for each condition\n",
    "for condition, results in manifold_results['individual_results'].items():\n",
    "    if 'embeddings' in results and len(results['embeddings']) > 0:\n",
    "        print(f\"\\nVisualizing embeddings for {condition}...\")\n",
    "        \n",
    "        embeddings = results['embeddings']\n",
    "        time_vector = results.get('time_vector', None)\n",
    "        \n",
    "        # Create embedding comparison plot\n",
    "        embedding_data = {}\n",
    "        for method, emb_result in embeddings.items():\n",
    "            if 'embedding' in emb_result:\n",
    "                embedding_data[method] = emb_result['embedding']\n",
    "        \n",
    "        if len(embedding_data) > 0:\n",
    "            fig = plotter.plot_manifold_comparison(\n",
    "                embedding_data,\n",
    "                labels=time_vector\n",
    "            )\n",
    "            plt.suptitle(f'Manifold Embeddings - {condition.title()}', fontsize=16)\n",
    "            plt.show()\n",
    "        \n",
    "        # Show PCA variance explained if available\n",
    "        if 'PCA' in embeddings and 'explained_variance_ratio' in embeddings['PCA']:\n",
    "            fig = plotter.plot_dimensionality_analysis(\n",
    "                embeddings['PCA']['explained_variance_ratio'],\n",
    "                method_name='PCA'\n",
    "            )\n",
    "            plt.suptitle(f'PCA Dimensionality Analysis - {condition.title()}', fontsize=14)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cross-Condition Analysis and Classification\n",
    "\n",
    "Let's examine how well we can distinguish between experimental conditions based on their neural dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine cross-condition comparison results\n",
    "if 'comparison' in manifold_results and len(manifold_results['comparison']) > 0:\n",
    "    comparison = manifold_results['comparison']\n",
    "    \n",
    "    print(\"=== Cross-Condition Analysis Results ===\")\n",
    "    \n",
    "    # Classification analysis\n",
    "    if 'classification_analysis' in comparison:\n",
    "        classification = comparison['classification_analysis']\n",
    "        \n",
    "        if 'classification_scores' in classification:\n",
    "            print(\"\\nClassification Accuracy (Cross-Validation):\")\n",
    "            \n",
    "            for method, classifiers in classification['classification_scores'].items():\n",
    "                print(f\"\\n{method}:\")\n",
    "                for clf_name, scores in classifiers.items():\n",
    "                    accuracy = scores.get('mean_accuracy', np.nan)\n",
    "                    std_acc = scores.get('std_accuracy', np.nan)\n",
    "                    print(f\"  {clf_name}: {accuracy:.3f} Â± {std_acc:.3f}\")\n",
    "    \n",
    "    # Manifold alignment analysis\n",
    "    if 'manifold_alignment' in comparison:\n",
    "        alignment = comparison['manifold_alignment']\n",
    "        \n",
    "        if 'alignment_scores' in alignment:\n",
    "            print(\"\\n\\nManifold Alignment Scores:\")\n",
    "            \n",
    "            for method, alignments in alignment['alignment_scores'].items():\n",
    "                if alignments:\n",
    "                    print(f\"\\n{method}:\")\n",
    "                    for comparison_name, alignment_data in alignments.items():\n",
    "                        mse = alignment_data.get('procrustes_mse', np.nan)\n",
    "                        corr = alignment_data.get('mean_correlation', np.nan)\n",
    "                        print(f\"  {comparison_name}: MSE={mse:.4f}, Corr={corr:.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"Cross-condition comparison not available or failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Importance Analysis\n",
    "\n",
    "Identify which metrics are most discriminative between conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance for discriminating conditions\n",
    "try:\n",
    "    from mea_flow.manifold.comparison import identify_discriminative_features\n",
    "    \n",
    "    # Extract individual condition results for feature analysis\n",
    "    individual_results = manifold_results.get('individual_results', {})\n",
    "    \n",
    "    if len(individual_results) >= 2:\n",
    "        print(\"Analyzing discriminative features...\")\n",
    "        \n",
    "        # Identify most important population statistics\n",
    "        feature_importance = identify_discriminative_features(\n",
    "            individual_results,\n",
    "            feature_type='population_statistics'\n",
    "        )\n",
    "        \n",
    "        if not feature_importance.empty:\n",
    "            print(\"\\n=== Most Discriminative Features ===\")\n",
    "            print(feature_importance.head(10))\n",
    "            \n",
    "            # Plot feature importance\n",
    "            if len(feature_importance) > 0:\n",
    "                fig = plotter.plot_feature_importance(\n",
    "                    feature_importance.head(10),\n",
    "                    top_n=10\n",
    "                )\n",
    "                plt.show()\n",
    "        else:\n",
    "            print(\"No discriminative features could be computed.\")\n",
    "    else:\n",
    "        print(\"Need at least 2 conditions for feature importance analysis.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Feature importance analysis failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Well-Based Analysis\n",
    "\n",
    "Analyze activity patterns at the individual well level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform well-based analysis for one condition\n",
    "example_condition = 'control'\n",
    "if example_condition in spike_lists:\n",
    "    print(f\"Performing well-based analysis for {example_condition}...\")\n",
    "    \n",
    "    spike_list = spike_lists[example_condition]\n",
    "    \n",
    "    # Compute metrics per well\n",
    "    well_metrics = metrics_analyzer.compute_all_metrics(\n",
    "        spike_list,\n",
    "        grouping='well'\n",
    "    )\n",
    "    \n",
    "    if not well_metrics.empty:\n",
    "        print(f\"\\nWell-based metrics computed for {len(well_metrics)} wells\")\n",
    "        print(well_metrics[['group_id', 'n_channels', 'mean_firing_rate', 'cv_isi_mean']].round(3))\n",
    "        \n",
    "        # Create well activity visualization\n",
    "        fig = plotter.plot_well_activity(\n",
    "            spike_list,\n",
    "            time_window=5.0\n",
    "        )\n",
    "        plt.show()\n",
    "        \n",
    "        # Create electrode map for the first well\n",
    "        fig = plotter.plot_electrode_map(\n",
    "            spike_list,\n",
    "            metric='firing_rate',\n",
    "            well_id=1\n",
    "        )\n",
    "        plt.show()\n",
    "    \n",
    "    else:\n",
    "        print(\"No well-based metrics could be computed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Time-Resolved Analysis\n",
    "\n",
    "Examine how metrics change over time within recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform time-resolved analysis\n",
    "print(\"Performing time-resolved analysis...\")\n",
    "\n",
    "time_window_length = 30.0  # 30-second windows\n",
    "\n",
    "for condition, spike_list in spike_lists.items():\n",
    "    print(f\"\\nAnalyzing temporal dynamics for {condition}...\")\n",
    "    \n",
    "    # Compute metrics over time windows\n",
    "    time_metrics = metrics_analyzer.compute_all_metrics(\n",
    "        spike_list,\n",
    "        grouping='time',\n",
    "        group_params={'window_length': time_window_length}\n",
    "    )\n",
    "    \n",
    "    if not time_metrics.empty and len(time_metrics) > 2:\n",
    "        print(f\"  Computed metrics for {len(time_metrics)} time windows\")\n",
    "        \n",
    "        # Plot temporal evolution of key metrics\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        metrics_to_plot = ['mean_firing_rate', 'cv_isi_mean', 'pearson_cc_mean', 'active_channels_count']\n",
    "        \n",
    "        for i, metric in enumerate(metrics_to_plot):\n",
    "            if metric in time_metrics.columns:\n",
    "                ax = axes[i]\n",
    "                \n",
    "                time_points = time_metrics['window_start'] + time_window_length/2\n",
    "                values = time_metrics[metric]\n",
    "                \n",
    "                ax.plot(time_points, values, 'o-', linewidth=2, markersize=6)\n",
    "                ax.set_xlabel('Time (s)')\n",
    "                ax.set_ylabel(metric.replace('_', ' ').title())\n",
    "                ax.grid(True, alpha=0.3)\n",
    "                ax.set_title(f'{metric.replace(\"_\", \" \").title()} Over Time')\n",
    "        \n",
    "        plt.suptitle(f'Temporal Dynamics - {condition.title()}', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    else:\n",
    "        print(f\"  Insufficient data for temporal analysis in {condition}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary and Results Export\n",
    "\n",
    "Summarize the key findings and demonstrate how to export results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary\n",
    "print(\"=== MEA-Flow Analysis Summary ===\")\n",
    "print(f\"\\nAnalyzed Conditions: {list(spike_lists.keys())}\")\n",
    "print(f\"Recording Duration: {list(spike_lists.values())[0].recording_length} seconds\")\n",
    "print(f\"Total Channels: {len(list(spike_lists.values())[0].channel_ids)}\")\n",
    "\n",
    "# Summary statistics table\n",
    "summary_stats = []\n",
    "for condition, spike_list in spike_lists.items():\n",
    "    stats = {\n",
    "        'Condition': condition,\n",
    "        'Active_Channels': len(spike_list.get_active_channels()),\n",
    "        'Total_Spikes': sum(train.n_spikes for train in spike_list.spike_trains.values()),\n",
    "        'Mean_Rate_Hz': np.mean([train.firing_rate for train in spike_list.spike_trains.values() if train.n_spikes > 0])\n",
    "    }\n",
    "    summary_stats.append(stats)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_stats)\n",
    "print(\"\\n=== Condition Summary ===\")\n",
    "print(summary_df.round(2))\n",
    "\n",
    "# Key findings from metrics\n",
    "if not all_metrics.empty:\n",
    "    print(\"\\n=== Key Metric Differences ===\")\n",
    "    \n",
    "    for metric in ['mean_firing_rate', 'cv_isi_mean', 'pearson_cc_mean']:\n",
    "        if metric in all_metrics.columns:\n",
    "            values = all_metrics.groupby('condition')[metric].mean()\n",
    "            print(f\"\\n{metric.replace('_', ' ').title()}:\")\n",
    "            for condition, value in values.items():\n",
    "                print(f\"  {condition}: {value:.4f}\")\n",
    "\n",
    "print(\"\\n=== Export Results ===\")\n",
    "\n",
    "# Demonstrate saving results\n",
    "try:\n",
    "    from mea_flow.utils.io import save_results, export_to_format\n",
    "    \n",
    "    # Create results directory\n",
    "    results_dir = Path(\"./mea_flow_results\")\n",
    "    results_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Export metrics to CSV\n",
    "    if not all_metrics.empty:\n",
    "        export_to_format(\n",
    "            all_metrics,\n",
    "            results_dir / \"metrics_summary.csv\",\n",
    "            format='csv'\n",
    "        )\n",
    "        print(\"âœ“ Metrics exported to metrics_summary.csv\")\n",
    "    \n",
    "    # Save complete results\n",
    "    complete_results = {\n",
    "        'metrics': all_metrics,\n",
    "        'manifold_results': manifold_results,\n",
    "        'summary_statistics': summary_df,\n",
    "        'analysis_config': config.__dict__,\n",
    "        'conditions_analyzed': list(spike_lists.keys())\n",
    "    }\n",
    "    \n",
    "    save_results(\n",
    "        complete_results,\n",
    "        results_dir / \"complete_analysis.pkl\"\n",
    "    )\n",
    "    print(\"âœ“ Complete results saved to complete_analysis.pkl\")\n",
    "    \n",
    "    print(f\"\\nAll results saved to: {results_dir.absolute()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Export failed: {e}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ MEA-Flow Tutorial Completed Successfully! ðŸŽ‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Next Steps and Advanced Usage\n",
    "\n",
    "This tutorial covered the basic workflow of MEA-Flow. Here are some directions for further analysis:\n",
    "\n",
    "### Advanced Analysis Options:\n",
    "\n",
    "1. **Custom Parameter Sets**: Use `get_analysis_presets()` for specialized analysis types\n",
    "2. **Detailed Manifold Analysis**: Explore additional dimensionality reduction methods\n",
    "3. **Network Burst Analysis**: Examine burst dynamics in detail\n",
    "4. **Cross-Temporal Analysis**: Compare dynamics across different time periods\n",
    "5. **Multi-Scale Analysis**: Analyze at different temporal resolutions\n",
    "\n",
    "### Loading Real Data:\n",
    "\n",
    "```python\n",
    "# Load Axion .spk files (after MATLAB conversion)\n",
    "spike_list = load_data('path/to/data.mat', \n",
    "                     channels_key='Channels',\n",
    "                     times_key='Times')\n",
    "\n",
    "# Load multiple files\n",
    "file_paths = ['condition1.mat', 'condition2.mat', 'condition3.mat']\n",
    "condition_names = ['Control', 'Treatment1', 'Treatment2']\n",
    "spike_lists = load_multiple_files(file_paths, condition_names)\n",
    "```\n",
    "\n",
    "### Statistical Analysis:\n",
    "\n",
    "For rigorous statistical comparisons, consider:\n",
    "- Multiple comparison corrections\n",
    "- Non-parametric tests for non-normal distributions\n",
    "- Effect size calculations\n",
    "- Bootstrap confidence intervals\n",
    "\n",
    "### Performance Optimization:\n",
    "\n",
    "For large datasets:\n",
    "- Use time windowing to reduce computational load\n",
    "- Limit the number of manifold learning methods\n",
    "- Reduce the number of pairs for synchrony analysis\n",
    "- Use parallel processing where available\n",
    "\n",
    "Refer to the MEA-Flow documentation for detailed API reference and additional examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}